{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일을 읽기 모드로 열기\n",
    "with open('/disk1/data/ing_mlm_data/processed/v3_ing_title_tag/train.txt', 'r', encoding='utf-8') as file:\n",
    "    data = file.read()  # 전체 내용을 읽습니다.\n",
    "    train = data.splitlines()  # 줄 단위로 나누어 리스트로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일을 읽기 모드로 열기\n",
    "with open('/disk1/data/ing_mlm_data/processed/v3_ing_title_tag/val.txt', 'r', encoding='utf-8') as file:\n",
    "    data = file.read()  # 전체 내용을 읽습니다.\n",
    "    val = data.splitlines()  # 줄 단위로 나누어 리스트로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일을 읽기 모드로 열기\n",
    "with open('/disk1/data/ing_mlm_data/processed/v3_ing_title_tag/test.txt', 'r', encoding='utf-8') as file:\n",
    "    data = file.read()  # 전체 내용을 읽습니다.\n",
    "    test = data.splitlines()  # 줄 단위로 나누어 리스트로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326521\n",
      "70399\n",
      "70228\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(val))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netx token prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TSV 파일을 읽기\n",
    "df = pd.read_csv('/home/donghee/projects/mlm/tester/test_output/ingr_title_tag_tokenizer_nMASK/ing_title_tag_125K_with_tagtokenizer_2023_0925-0-0.38259474338014265-0.2867754088534977-0.510488911721894-0.5977395324942204-46716.tsv', sep='\\t', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /home/donghee/projects/mlm/tester/test_output/ingr_title_tag_tokenizer_nMASK/ing_title_tag_125K_with_tagtokenizer_2023_0925-0-0.38259474338014265-0.2867754088534977-0.510488911721894-0.5977395324942204-46716.tsv\n",
      "Top 5 Predicted #0:\n",
      "predicted #0\n",
      "apples             171\n",
      "cocoa              167\n",
      "elbow_macaroni     133\n",
      "shortening         128\n",
      "enchilada_sauce    128\n",
      "pie_crusts         126\n",
      "bread_flour        126\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------\n",
      "File: /home/donghee/projects/mlm/tester/test_output/ingr_title_tag_tokenizer_nMASK/ing_title_tag_125K_with_tagtokenizer_2023_0925-1-0.26554894519672106-0.18766589605274425-0.37010874218683104-0.4449439164312013-46716.tsv\n",
      "Top 5 Predicted #0:\n",
      "predicted #0\n",
      "shortening                           228\n",
      "vanilla                              199\n",
      "powdered_sugar                       192\n",
      "boneless_chicken_breasts             191\n",
      "chocolate_chips                      179\n",
      "boneless_skinless_chicken_breasts    165\n",
      "cheddar_cheese                       165\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------\n",
      "File: /home/donghee/projects/mlm/tester/test_output/ingr_title_tag_tokenizer_nMASK/ing_title_tag_125K_with_tagtokenizer_2023_0925-2-0.23206506523036685-0.16660244883979794-0.31757855980820276-0.39688757599109514-46716.tsv\n",
      "Top 5 Predicted #0:\n",
      "predicted #0\n",
      "milk               454\n",
      "vanilla            407\n",
      "egg                390\n",
      "vanilla_extract    346\n",
      "bacon              316\n",
      "cream_cheese       306\n",
      "powdered_sugar     289\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------\n",
      "File: /home/donghee/projects/mlm/tester/test_output/ingr_title_tag_tokenizer_nMASK/ing_title_tag_125K_with_tagtokenizer_2023_0925-3-0.2142907259944276-0.15285983388988783-0.2947812312698005-0.3689100094186146-46716.tsv\n",
      "Top 5 Predicted #0:\n",
      "predicted #0\n",
      "milk       775\n",
      "egg        613\n",
      "sugar      590\n",
      "butter     583\n",
      "vanilla    527\n",
      "water      522\n",
      "flour      484\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# 파일 목록 설정 (예시)\n",
    "file_list = ['/home/donghee/projects/mlm/tester/test_output/ingr_title_tag_tokenizer_nMASK/ing_title_tag_125K_with_tagtokenizer_2023_0925-0-0.38259474338014265-0.2867754088534977-0.510488911721894-0.5977395324942204-46716.tsv', '/home/donghee/projects/mlm/tester/test_output/ingr_title_tag_tokenizer_nMASK/ing_title_tag_125K_with_tagtokenizer_2023_0925-1-0.26554894519672106-0.18766589605274425-0.37010874218683104-0.4449439164312013-46716.tsv', '/home/donghee/projects/mlm/tester/test_output/ingr_title_tag_tokenizer_nMASK/ing_title_tag_125K_with_tagtokenizer_2023_0925-2-0.23206506523036685-0.16660244883979794-0.31757855980820276-0.39688757599109514-46716.tsv', '/home/donghee/projects/mlm/tester/test_output/ingr_title_tag_tokenizer_nMASK/ing_title_tag_125K_with_tagtokenizer_2023_0925-3-0.2142907259944276-0.15285983388988783-0.2947812312698005-0.3689100094186146-46716.tsv']  # 처리할 파일 목록\n",
    "\n",
    "summary = []  # 파일별 통계를 저장할 리스트\n",
    "\n",
    "# 각 파일에 대해 반복 처리\n",
    "for file in file_list:\n",
    "    # 파일 로드\n",
    "    df = pd.read_csv(file, sep='\\t', encoding='utf-8')\n",
    "    \n",
    "    # 'predicted #0'에 대한 통계 계산\n",
    "    predicted_0_counts = df['predicted #0'].value_counts()\n",
    "    \n",
    "    # 통계를 요약하여 리스트에 저장\n",
    "    summary.append({\n",
    "        'file': file,\n",
    "        'top_5_predicted': predicted_0_counts.head(7)  # 상위 5개만 추출\n",
    "    })\n",
    "    \n",
    "    # 막대 그래프 그리기\n",
    "    # predicted_0_counts.plot(kind='bar', title=f'{file} - Predicted #0 Counts')\n",
    "    # plt.xlabel('Predicted #0')\n",
    "    # plt.ylabel('Frequency')\n",
    "    # plt.show()\n",
    "\n",
    "# 파일별 상위 5개 예측값 출력\n",
    "for result in summary:\n",
    "    print(f\"File: {result['file']}\")\n",
    "    print(\"Top 5 Predicted #0:\")\n",
    "    print(result['top_5_predicted'])\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   count  count  count  count\n",
      "predicted #0                                                 \n",
      "apples                             171.0    NaN    NaN    NaN\n",
      "cocoa                              167.0    NaN    NaN    NaN\n",
      "elbow_macaroni                     133.0    NaN    NaN    NaN\n",
      "shortening                         128.0  228.0    NaN    NaN\n",
      "enchilada_sauce                    128.0    NaN    NaN    NaN\n",
      "pie_crusts                         126.0    NaN    NaN    NaN\n",
      "bread_flour                        126.0    NaN    NaN    NaN\n",
      "vanilla                              NaN  199.0  407.0  527.0\n",
      "powdered_sugar                       NaN  192.0  289.0    NaN\n",
      "boneless_chicken_breasts             NaN  191.0    NaN    NaN\n",
      "chocolate_chips                      NaN  179.0    NaN    NaN\n",
      "boneless_skinless_chicken_breasts    NaN  165.0    NaN    NaN\n",
      "cheddar_cheese                       NaN  165.0    NaN    NaN\n",
      "milk                                 NaN    NaN  454.0  775.0\n",
      "egg                                  NaN    NaN  390.0  613.0\n",
      "vanilla_extract                      NaN    NaN  346.0    NaN\n",
      "bacon                                NaN    NaN  316.0    NaN\n",
      "cream_cheese                         NaN    NaN  306.0    NaN\n",
      "sugar                                NaN    NaN    NaN  590.0\n",
      "butter                               NaN    NaN    NaN  583.0\n",
      "water                                NaN    NaN    NaN  522.0\n",
      "flour                                NaN    NaN    NaN  484.0\n"
     ]
    }
   ],
   "source": [
    "# 모든 파일에서 공통으로 등장하는 예측값 확인\n",
    "all_predicted = pd.concat([pd.DataFrame(summary[i]['top_7_predicted']) for i in range(len(summary))], axis=1)\n",
    "print(all_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto-regressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TSV 파일을 읽기\n",
    "df = pd.read_csv('/home/donghee/projects/mlm/tester/test_output/10-next_token_predict_2023_1030_all.tsv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDX</th>\n",
       "      <th>ORIGINAL</th>\n",
       "      <th>INPUT</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ANSWER_LIST</th>\n",
       "      <th>PRED_LIST_TEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fontina_cheese fresh_basil_leaves elbow_macaro...</td>\n",
       "      <td>alfredo_sauce parmesan_cheese milk butter salt...</td>\n",
       "      <td>Pesto Shrimp Mac and Cheese</td>\n",
       "      <td>['Fontina_cheese', 'fresh_basil_leaves', 'elbo...</td>\n",
       "      <td>['alfredo_sauce', 'parmesan_cheese', 'milk', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>yellow_bell_peppers low_sodium_soy_sauce brocc...</td>\n",
       "      <td>vegetable_oil garlic_cloves water salt sugar b...</td>\n",
       "      <td>Shrimp Stir Fry</td>\n",
       "      <td>['yellow_bell_peppers', 'low_sodium_soy_sauce'...</td>\n",
       "      <td>['vegetable_oil', 'garlic_cloves', 'water', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pork_chops cooking_oil apples brown_sugar cinn...</td>\n",
       "      <td>apple_pie_filling pork_chops water butter salt...</td>\n",
       "      <td>Pork Chops and Apples</td>\n",
       "      <td>['pork_chops', 'cooking_oil', 'apples', 'brown...</td>\n",
       "      <td>['apple_pie_filling', 'pork_chops', 'water', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>havarti_cheese boneless_chicken_breasts roma_t...</td>\n",
       "      <td>romaine_lettuce chicken_breasts parmesan_chees...</td>\n",
       "      <td>Chopped Salad</td>\n",
       "      <td>['havarti_cheese', 'boneless_chicken_breasts',...</td>\n",
       "      <td>['romaine_lettuce', 'chicken_breasts', 'parmes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>port_wine blackberries beef_broth shallot hone...</td>\n",
       "      <td>blackberries sugar butter salt water eggs flou...</td>\n",
       "      <td>Blackberry port wine sauce</td>\n",
       "      <td>['port_wine', 'blackberries', 'beef_broth', 's...</td>\n",
       "      <td>['blackberries', 'sugar', 'butter', 'salt', 'w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDX                                           ORIGINAL  \\\n",
       "0    1  Fontina_cheese fresh_basil_leaves elbow_macaro...   \n",
       "1    2  yellow_bell_peppers low_sodium_soy_sauce brocc...   \n",
       "2    3  pork_chops cooking_oil apples brown_sugar cinn...   \n",
       "3    4  havarti_cheese boneless_chicken_breasts roma_t...   \n",
       "4    5  port_wine blackberries beef_broth shallot hone...   \n",
       "\n",
       "                                               INPUT  \\\n",
       "0  alfredo_sauce parmesan_cheese milk butter salt...   \n",
       "1  vegetable_oil garlic_cloves water salt sugar b...   \n",
       "2  apple_pie_filling pork_chops water butter salt...   \n",
       "3  romaine_lettuce chicken_breasts parmesan_chees...   \n",
       "4  blackberries sugar butter salt water eggs flou...   \n",
       "\n",
       "                         TITLE  \\\n",
       "0  Pesto Shrimp Mac and Cheese   \n",
       "1              Shrimp Stir Fry   \n",
       "2        Pork Chops and Apples   \n",
       "3                Chopped Salad   \n",
       "4   Blackberry port wine sauce   \n",
       "\n",
       "                                         ANSWER_LIST  \\\n",
       "0  ['Fontina_cheese', 'fresh_basil_leaves', 'elbo...   \n",
       "1  ['yellow_bell_peppers', 'low_sodium_soy_sauce'...   \n",
       "2  ['pork_chops', 'cooking_oil', 'apples', 'brown...   \n",
       "3  ['havarti_cheese', 'boneless_chicken_breasts',...   \n",
       "4  ['port_wine', 'blackberries', 'beef_broth', 's...   \n",
       "\n",
       "                                      PRED_LIST_TEMP  \n",
       "0  ['alfredo_sauce', 'parmesan_cheese', 'milk', '...  \n",
       "1  ['vegetable_oil', 'garlic_cloves', 'water', 's...  \n",
       "2  ['apple_pie_filling', 'pork_chops', 'water', '...  \n",
       "3  ['romaine_lettuce', 'chicken_breasts', 'parmes...  \n",
       "4  ['blackberries', 'sugar', 'butter', 'salt', 'w...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED_LIST_TEMP Index 0\n",
      "Top 7 Predicted Values:\n",
      "PRED_LIST_TEMP\n",
      "'eggs'                                 960\n",
      "'butter'                               660\n",
      "'boneless_skinless_chicken_breasts'    626\n",
      "'barbecue_sauce'                       560\n",
      "'milk'                                 483\n",
      "'zucchini'                             481\n",
      "'spaghetti_sauce'                      474\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------\n",
      "PRED_LIST_TEMP Index 1\n",
      "Top 7 Predicted Values:\n",
      "PRED_LIST_TEMP\n",
      "'butter'       4858\n",
      "'water'        2845\n",
      "'salt'         2727\n",
      "'sugar'        2535\n",
      "'eggs'         2212\n",
      "'olive_oil'    1954\n",
      "'milk'         1336\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------\n",
      "PRED_LIST_TEMP Index 2\n",
      "Top 7 Predicted Values:\n",
      "PRED_LIST_TEMP\n",
      "'salt'         10285\n",
      "'butter'        7977\n",
      "'water'         4074\n",
      "'sugar'         3955\n",
      "'olive_oil'     2484\n",
      "'eggs'          1716\n",
      "'milk'          1158\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------\n",
      "PRED_LIST_TEMP Index 3\n",
      "Top 7 Predicted Values:\n",
      "PRED_LIST_TEMP\n",
      "'salt'             13850\n",
      "'butter'            9778\n",
      "'sugar'             6389\n",
      "'water'             4904\n",
      "'olive_oil'         2327\n",
      "'eggs'              1768\n",
      "'garlic_cloves'      912\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------\n",
      "모든 인덱스에서 공통으로 등장한 예측값:\n",
      "                Index_0  Index_1  Index_2  Index_3\n",
      "PRED_LIST_TEMP                                    \n",
      "'eggs'            960.0   2212.0   1716.0   1768.0\n",
      "'butter'          660.0   4858.0   7977.0   9778.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 파일 로드 (예시)\n",
    "# df = pd.read_csv('file.csv')\n",
    "\n",
    "# 인덱스별 통계를 저장할 리스트\n",
    "summary = []\n",
    "\n",
    "# 꺽쇠([]) 제거 함수\n",
    "def clean_text(text):\n",
    "    return text.replace('[', '').replace(']', '').strip()\n",
    "\n",
    "# 0번 인덱스 값에 대한 통계 계산 (PRED_LIST_TEMP를 쉼표로 split하여 0번째 값 추출)\n",
    "pred_0_counts = df['PRED_LIST_TEMP'].apply(lambda x: clean_text(x.split(',')[0]) if len(x.split(',')) > 0 else None).value_counts()\n",
    "summary.append({\n",
    "    'index': 0,\n",
    "    'top_7_predicted': pred_0_counts.head(7)  # 상위 7개만 추출\n",
    "})\n",
    "\n",
    "# 1번 인덱스 값에 대한 통계 계산\n",
    "pred_1_counts = df['PRED_LIST_TEMP'].apply(lambda x: clean_text(x.split(',')[1]) if len(x.split(',')) > 1 else None).value_counts()\n",
    "summary.append({\n",
    "    'index': 1,\n",
    "    'top_7_predicted': pred_1_counts.head(7)\n",
    "})\n",
    "\n",
    "# 2번 인덱스 값에 대한 통계 계산\n",
    "pred_2_counts = df['PRED_LIST_TEMP'].apply(lambda x: clean_text(x.split(',')[2]) if len(x.split(',')) > 2 else None).value_counts()\n",
    "summary.append({\n",
    "    'index': 2,\n",
    "    'top_7_predicted': pred_2_counts.head(7)\n",
    "})\n",
    "\n",
    "# 3번 인덱스 값에 대한 통계 계산\n",
    "pred_3_counts = df['PRED_LIST_TEMP'].apply(lambda x: clean_text(x.split(',')[3]) if len(x.split(',')) > 3 else None).value_counts()\n",
    "summary.append({\n",
    "    'index': 3,\n",
    "    'top_7_predicted': pred_3_counts.head(7)\n",
    "})\n",
    "\n",
    "# 시각화\n",
    "# for idx, result in enumerate(summary):\n",
    "#     # 막대 그래프 그리기\n",
    "#     result['top_7_predicted'].plot(kind='bar', title=f'PRED_LIST_TEMP Index {result[\"index\"]} - Top 7 Counts')\n",
    "#     plt.xlabel(f'PRED_LIST_TEMP Index {result[\"index\"]}')\n",
    "#     plt.ylabel('Frequency')\n",
    "#     plt.show()\n",
    "\n",
    "# 상위 7개 예측값 출력\n",
    "for result in summary:\n",
    "    print(f\"PRED_LIST_TEMP Index {result['index']}\")\n",
    "    print(\"Top 7 Predicted Values:\")\n",
    "    print(result['top_7_predicted'])\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 모든 인덱스에서 공통으로 등장하는 예측값 확인\n",
    "# 각 인덱스별 상위 7개 예측값을 하나의 데이터프레임으로 통합\n",
    "all_predicted = pd.concat([pd.DataFrame(summary[i]['top_7_predicted']) for i in range(len(summary))], axis=1)\n",
    "\n",
    "# 열 이름을 인덱스로 매핑하여 가독성을 높임\n",
    "all_predicted.columns = [f'Index_{summary[i][\"index\"]}' for i in range(len(summary))]\n",
    "\n",
    "# 공통 예측값을 확인 (모든 인덱스에서 공통으로 등장하는 값)\n",
    "common_predicted = all_predicted.dropna()  # NaN이 아닌 공통 값을 필터링\n",
    "\n",
    "print(\"모든 인덱스에서 공통으로 등장한 예측값:\")\n",
    "print(common_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     count   count    count    count\n",
      "PRED_LIST_TEMP                                                      \n",
      "'eggs'                               960.0  2212.0   1716.0   1768.0\n",
      "'butter'                             660.0  4858.0   7977.0   9778.0\n",
      "'boneless_skinless_chicken_breasts'  626.0     0.0      0.0      0.0\n",
      "'barbecue_sauce'                     560.0     0.0      0.0      0.0\n",
      "'milk'                               483.0  1336.0   1158.0      0.0\n",
      "'zucchini'                           481.0     0.0      0.0      0.0\n",
      "'spaghetti_sauce'                    474.0     0.0      0.0      0.0\n",
      "'water'                                0.0  2845.0   4074.0   4904.0\n",
      "'salt'                                 0.0  2727.0  10285.0  13850.0\n",
      "'sugar'                                0.0  2535.0   3955.0   6389.0\n",
      "'olive_oil'                            0.0  1954.0   2484.0   2327.0\n",
      "'garlic_cloves'                        0.0     0.0      0.0    912.0\n"
     ]
    }
   ],
   "source": [
    "# 각 인덱스별 상위 7개 예측값을 하나의 데이터프레임으로 통합\n",
    "all_predicted = pd.concat([pd.DataFrame(summary[i]['top_7_predicted']) for i in range(len(summary))], axis=1)\n",
    "\n",
    "# 열 이름을 인덱스로 매핑하여 가독성을 높임\n",
    "all_predicted.columns = [f'count' for i in range(len(summary))]\n",
    "\n",
    "# NaN 값은 0으로 채우기\n",
    "all_predicted = all_predicted.fillna(0)\n",
    "\n",
    "# 결과 출력\n",
    "print(all_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
